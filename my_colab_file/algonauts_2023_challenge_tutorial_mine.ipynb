{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/kN9Fk9R756qjz5bv9fK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boxed-mikann/transformer_brain_encoder/blob/main/my_colab_file/algonauts_2023_challenge_tutorial_mine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8hej6J1ukOj6"
      },
      "outputs": [],
      "source": [
        "platform = 'colab' #@param ['colab', 'jupyter_notebook'] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VIRDC8bxKiw",
        "outputId": "9fde7b77-81a1-4932-df01-9d9ebd6a18ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.5.2 in /usr/local/lib/python3.12/dist-packages (3.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.2) (1.17.0)\n",
            "Requirement already satisfied: nilearn==0.9.2 in /usr/local/lib/python3.12/dist-packages (0.9.2)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (1.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (5.4.0)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (5.3.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (2.2.2)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (1.16.3)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel>=3.0.0->nilearn==0.9.2) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel>=3.0.0->nilearn==0.9.2) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->nilearn==0.9.2) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->nilearn==0.9.2) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "if platform == 'colab':\n",
        "    !pip install matplotlib==3.5.2\n",
        "    !pip install nilearn==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G4ze_dIrxRN_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "matplotlib.use('Agg') # Force a non-interactive backend to potentially resolve conflicts\n",
        "from matplotlib import pyplot as plt\n",
        "from nilearn import datasets\n",
        "from nilearn import plotting\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
        "from torchvision import transforms\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import pearsonr as corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAypi_tExXsC",
        "outputId": "eb925c45-3761-492f-b0f9-20dc6bbfcd08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "if platform == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    data_dir = '/content/drive/MyDrive/algonauts_2023_tutorial_data' #@param {type:\"string\"}\n",
        "    parent_submission_dir = '/content/drive/MyDrive/algonauts_2023_challenge_submission' #@param {type:\"string\"}\n",
        "    result_dir = '/content/drive/MyDrive/algonauts_2023/transformer_brain_encoder_results' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W4pnh3exxizF"
      },
      "outputs": [],
      "source": [
        "device = 'cpu' #@param ['cpu', 'cuda'] {allow-input: true}\n",
        "device = torch.device(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59FdnRWrHiEG",
        "outputId": "b34dab0d-60f8-4cc3-e5a1-20ec6dd57ccb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.23.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.6.2)\n",
            "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (1.0.22)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.10.5)\n",
            "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 open_clip_torch-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_DIR = '/content/transformer_brain_encoder'\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !cd /content && git clone https://github.com/Hosseinadeli/transformer_brain_encoder.git\n",
        "#!python main.py --run 1  --subj 1 --enc_output_layer 1 --readout_res 'rois_all'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0H3cputjD9D",
        "outputId": "3dddab89-a596-46c1-f9fc-72ad97d52bd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformer_brain_encoder'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 246 (delta 6), reused 10 (delta 4), pack-reused 231 (from 1)\u001b[K\n",
            "Receiving objects: 100% (246/246), 51.72 MiB | 23.58 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XsvT0SrMxd1h"
      },
      "outputs": [],
      "source": [
        "class argObj:\n",
        "  def __init__(self, data_dir, parent_submission_dir, subj):\n",
        "\n",
        "    self.subj = format(subj, '02')\n",
        "    self.data_dir = os.path.join(data_dir, 'subj'+self.subj)\n",
        "    self.parent_submission_dir = parent_submission_dir\n",
        "    self.subject_submission_dir = os.path.join(self.parent_submission_dir,\n",
        "        'subj'+self.subj)\n",
        "\n",
        "    # Create the submission directory if not existing\n",
        "    if not os.path.isdir(self.subject_submission_dir):\n",
        "        os.makedirs(self.subject_submission_dir)\n",
        "\n",
        "args = argObj(data_dir, result_dir, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U_pMXFyX0G56",
        "outputId": "e5ba2a22-abaf-4173-ad12-41daee082237"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/algonauts_2023_tutorial_data/subj01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/transformer_brain_encoder && python main.py \\\n",
        "  --run 1  \\\n",
        "  --subj $args.subj \\\n",
        "  --enc_output_layer 1 \\\n",
        "  --readout_res 'rois_all' \\\n",
        "  --data_dir $data_dir \\\n",
        "  --output_path $args.subject_submission_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-WsmCPzumMj",
        "outputId": "7613a59f-11bf-431c-b687-c2b5b3da87e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "roi_name_maps: [{0: 'Unknown', 1: 'V1v', 2: 'V1d', 3: 'V2v', 4: 'V2d', 5: 'V3v', 6: 'V3d', 7: 'hV4'}, {0: 'Unknown', 1: 'EBA', 2: 'FBA-1', 3: 'FBA-2', 4: 'mTL-bodies'}, {0: 'Unknown', 1: 'OFA', 2: 'FFA-1', 3: 'FFA-2', 4: 'mTL-faces', 5: 'aTL-faces'}, {0: 'Unknown', 1: 'OPA', 2: 'PPA', 3: 'RSC'}, {0: 'Unknown', 1: 'OWFA', 2: 'VWFA-1', 3: 'VWFA-2', 4: 'mfs-words', 5: 'mTL-words'}, {0: 'Unknown', 1: 'early', 2: 'midventral', 3: 'midlateral', 4: 'midparietal', 5: 'ventral', 6: 'lateral', 7: 'parietal'}]\n",
            "lh_challenge_rois: 6\n",
            "lh_challenge_rois_s: torch.Size([25, 19004])\n",
            "Training stimulus images: 8857\n",
            "Validation stimulus images: 984\n",
            "\n",
            "Test stimulus images: 159\n",
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth\n",
            "100% 330M/330M [00:01<00:00, 316MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/transformer_brain_encoder/main.py\", line 491, in <module>\n",
            "    main(0, 1, args)\n",
            "  File \"/content/transformer_brain_encoder/main.py\", line 292, in main\n",
            "    model = model.cuda() \n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1082, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 928, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 928, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 928, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 2 more times]\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 955, in _apply\n",
            "    param_applied = fn(param)\n",
            "                    ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1082, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "                                 ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\", line 412, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd /content/transformer_brain_encoder && python main.py \\\n",
        "  --subj args.subj \\\n",
        "  --run 1 \\\n",
        "  --data_dir '/content/drive/MyDrive/algonauts_2023_tutorial_data' \\\n",
        "  --dataset 'nsd_algo' \\\n",
        "  --backbone_arch 'dinov2_q' \\\n",
        "  --encoder_arch 'spatial_feature' \\\n",
        "  --readout_res 'rois_all' \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 8 \\\n",
        "  --image_size 224 \\\n",
        "  --output_path './results/' \\\n",
        "  --save_model 0 \\\n",
        "  --enc_output_layer 1 \\\n",
        "  --lr 0.0005 \\\n",
        "  --lr_drop 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Av7O-_XlnU_",
        "outputId": "f5cd103e-d173-4d41-bb7e-a779c50b2fc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "roi_name_maps: [{0: 'Unknown', 1: 'V1v', 2: 'V1d', 3: 'V2v', 4: 'V2d', 5: 'V3v', 6: 'V3d', 7: 'hV4'}, {0: 'Unknown', 1: 'EBA', 2: 'FBA-1', 3: 'FBA-2', 4: 'mTL-bodies'}, {0: 'Unknown', 1: 'OFA', 2: 'FFA-1', 3: 'FFA-2', 4: 'mTL-faces', 5: 'aTL-faces'}, {0: 'Unknown', 1: 'OPA', 2: 'PPA', 3: 'RSC'}, {0: 'Unknown', 1: 'OWFA', 2: 'VWFA-1', 3: 'VWFA-2', 4: 'mfs-words', 5: 'mTL-words'}, {0: 'Unknown', 1: 'early', 2: 'midventral', 3: 'midlateral', 4: 'midparietal', 5: 'ventral', 6: 'lateral', 7: 'parietal'}]\n",
            "lh_challenge_rois: 6\n",
            "lh_challenge_rois_s: torch.Size([25, 19004])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/transformer_brain_encoder/main.py\", line 491, in <module>\n",
            "    main(0, 1, args)\n",
            "  File \"/content/transformer_brain_encoder/main.py\", line 258, in main\n",
            "    train_loader, val_loader = fetch_dataloaders(args, train='train')\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/transformer_brain_encoder/datasets/nsd.py\", line 251, in fetch_dataloaders\n",
            "    algonauts_dataset(args,train, train_imgs_paths, idxs_train, transform_train), \n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/transformer_brain_encoder/datasets/nsd.py\", line 44, in __init__\n",
            "    rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\", line 484, in load\n",
            "    return format.read_array(fid, allow_pickle=allow_pickle,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/format.py\", line 836, in read_array\n",
            "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}