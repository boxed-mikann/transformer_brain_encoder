{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boxed-mikann/transformer_brain_encoder/blob/main/my_colab_file/algonauts_2023_challenge_tutorial_mine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8hej6J1ukOj6"
      },
      "outputs": [],
      "source": [
        "platform = 'colab' #@param ['colab', 'jupyter_notebook'] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VIRDC8bxKiw",
        "outputId": "e062897b-f798-4bc5-ca15-bb298d4e0718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib==3.5.2 in /usr/local/lib/python3.12/dist-packages (3.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.2) (1.17.0)\n",
            "Requirement already satisfied: nilearn==0.9.2 in /usr/local/lib/python3.12/dist-packages (0.9.2)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (1.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (5.4.0)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (5.3.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (2.2.2)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from nilearn==0.9.2) (1.16.3)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel>=3.0.0->nilearn==0.9.2) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel>=3.0.0->nilearn==0.9.2) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2->nilearn==0.9.2) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->nilearn==0.9.2) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->nilearn==0.9.2) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "if platform == 'colab':\n",
        "    !pip install matplotlib==3.5.2\n",
        "    !pip install nilearn==0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G4ze_dIrxRN_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "matplotlib.use('Agg') # Force a non-interactive backend to potentially resolve conflicts\n",
        "from matplotlib import pyplot as plt\n",
        "from nilearn import datasets\n",
        "from nilearn import plotting\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
        "from torchvision import transforms\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import pearsonr as corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAypi_tExXsC",
        "outputId": "96378738-9ec2-42e3-8b55-23b6064549b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "if platform == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/', force_remount=True)\n",
        "    data_dir = '/content/drive/MyDrive/algonauts_2023_tutorial_data' #@param {type:\"string\"}\n",
        "    parent_submission_dir = '/content/drive/MyDrive/algonauts_2023_challenge_submission' #@param {type:\"string\"}\n",
        "    result_dir = '/content/drive/MyDrive/algonauts_2023/transformer_brain_encoder_results' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W4pnh3exxizF"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' #@param ['cpu', 'cuda'] {allow-input: true}\n",
        "device = torch.device(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59FdnRWrHiEG",
        "outputId": "ff104fc7-efab-47b4-a959-9ee78d8f5247"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.23.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2024.11.6)\n",
            "Collecting ftfy (from open_clip_torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.6.2)\n",
            "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (1.0.22)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.10.5)\n",
            "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, open_clip_torch\n",
            "Successfully installed ftfy-6.3.1 open_clip_torch-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_DIR = '/content/transformer_brain_encoder'\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !cd /content && git clone https://github.com/Hosseinadeli/transformer_brain_encoder.git\n",
        "#!python main.py --run 1  --subj 1 --enc_output_layer 1 --readout_res 'rois_all'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0H3cputjD9D",
        "outputId": "2812ee5b-c226-48d7-d788-3dd20679ef96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformer_brain_encoder'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 246 (delta 6), reused 10 (delta 4), pack-reused 231 (from 1)\u001b[K\n",
            "Receiving objects: 100% (246/246), 51.72 MiB | 18.05 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.exists(REPO_DIR):\n",
        "    !cd \"{REPO_DIR}\" && git pull\n",
        "else:\n",
        "    print(f\"Repository directory not found: {REPO_DIR}\")"
      ],
      "metadata": {
        "id": "jvKo70UMEj6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XsvT0SrMxd1h"
      },
      "outputs": [],
      "source": [
        "class argObj:\n",
        "  def __init__(self, data_dir, parent_submission_dir, subj):\n",
        "\n",
        "    self.subj = format(subj, '02')\n",
        "    self.data_dir = os.path.join(data_dir, 'subj'+self.subj)\n",
        "    self.parent_submission_dir = parent_submission_dir\n",
        "    self.subject_submission_dir = os.path.join(self.parent_submission_dir,\n",
        "        'subj'+self.subj)\n",
        "\n",
        "    # Create the submission directory if not existing\n",
        "    if not os.path.isdir(self.subject_submission_dir):\n",
        "        os.makedirs(self.subject_submission_dir)\n",
        "\n",
        "args = argObj(data_dir, result_dir, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U_pMXFyX0G56",
        "outputId": "39f916b8-ddeb-47c5-fea1-af00f705c070"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/algonauts_2023_tutorial_data/subj01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_data=os.path.join(result_dir,'dino_v2')"
      ],
      "metadata": {
        "id": "fiHmPOwiMrMA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python extract_features_correct.py \\\n",
        "  --data_dir $args.data_dir \\\n",
        "  --output_dir $extracted_data \\\n",
        "  --subj '01' \\\n",
        "  --batch_size 16 \\\n",
        "  --device 'cuda' \\\n",
        "  --enc_layer -1"
      ],
      "metadata": {
        "id": "O0EWfWiLMNLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/transformer_brain_encoder && python main.py \\\n",
        "  --run 1  \\\n",
        "  --subj $args.subj \\\n",
        "  --enc_output_layer 1 \\\n",
        "  --readout_res 'rois_all' \\\n",
        "  --data_dir $data_dir \\\n",
        "  --output_path $args.subject_submission_dir\n",
        "  --save_model 1 \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-WsmCPzumMj",
        "outputId": "13e2ea6b-2caa-4bec-bf63-8b1d65e6f0cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "roi_name_maps: [{0: 'Unknown', 1: 'V1v', 2: 'V1d', 3: 'V2v', 4: 'V2d', 5: 'V3v', 6: 'V3d', 7: 'hV4'}, {0: 'Unknown', 1: 'EBA', 2: 'FBA-1', 3: 'FBA-2', 4: 'mTL-bodies'}, {0: 'Unknown', 1: 'OFA', 2: 'FFA-1', 3: 'FFA-2', 4: 'mTL-faces', 5: 'aTL-faces'}, {0: 'Unknown', 1: 'OPA', 2: 'PPA', 3: 'RSC'}, {0: 'Unknown', 1: 'OWFA', 2: 'VWFA-1', 3: 'VWFA-2', 4: 'mfs-words', 5: 'mTL-words'}, {0: 'Unknown', 1: 'early', 2: 'midventral', 3: 'midlateral', 4: 'midparietal', 5: 'ventral', 6: 'lateral', 7: 'parietal'}]\n",
            "lh_challenge_rois: 6\n",
            "lh_challenge_rois_s: torch.Size([25, 19004])\n",
            "Training stimulus images: 8857\n",
            "Validation stimulus images: 984\n",
            "\n",
            "Test stimulus images: 159\n",
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitb14_pretrain.pth\n",
            "100% 330M/330M [00:01<00:00, 295MB/s]\n",
            "Number of model parameters: 36805564\n",
            "brain_encoder(\n",
            "  (backbone_model): Joiner(\n",
            "    (0): dino_model_with_hooks(\n",
            "      (backbone): DinoVisionTransformer(\n",
            "        (patch_embed): PatchEmbed(\n",
            "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
            "          (norm): Identity()\n",
            "        )\n",
            "        (blocks): ModuleList(\n",
            "          (0-11): 12 x NestedTensorBlock(\n",
            "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "            (attn): MemEffAttention(\n",
            "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls1): LayerScale()\n",
            "            (drop_path1): Identity()\n",
            "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "            (mlp): Mlp(\n",
            "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (act): GELU(approximate='none')\n",
            "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (drop): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (ls2): LayerScale()\n",
            "            (drop_path2): Identity()\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (head): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): PositionEmbeddingSine()\n",
            "  )\n",
            "  (transformer): Transformer(\n",
            "    (decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (query_embed): Embedding(50, 768)\n",
            "  (lh_embed): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
            "  )\n",
            "  (rh_embed): Sequential(\n",
            "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
            "Start training\n",
            "Epoch: [0]  [  0/554]  eta: 1:58:12  lr: 0.000500  loss_labels: 1.8257 (1.8257)  loss: 1.8257 (1.8257)  time: 12.8015\n",
            "Epoch: [0]  [100/554]  eta: 0:36:17  lr: 0.000500  loss_labels: 0.9855 (1.0187)  loss: 0.9109 (1.0187)  time: 2.5864\n",
            "Epoch: [0]  [200/554]  eta: 0:21:27  lr: 0.000500  loss_labels: 0.8936 (0.9579)  loss: 0.8767 (0.9579)  time: 2.4942\n",
            "Epoch: [0]  [300/554]  eta: 0:13:34  lr: 0.000500  loss_labels: 0.8561 (0.9260)  loss: 0.8855 (0.9260)  time: 2.2043\n",
            "Epoch: [0]  [400/554]  eta: 0:07:44  lr: 0.000500  loss_labels: 0.7992 (0.8983)  loss: 0.7892 (0.8983)  time: 2.5037\n",
            "Epoch: [0]  [500/554]  eta: 0:02:36  lr: 0.000500  loss_labels: 0.8105 (0.8833)  loss: 0.8464 (0.8833)  time: 2.2571\n",
            "Epoch: [0]  [553/554]  eta: 0:00:02  lr: 0.000500  loss_labels: 0.8020 (0.8749)  loss: 0.7702 (0.8749)  time: 2.2970\n",
            "Epoch: [0] Total time: 0:26:19 (2.8512 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.8020 (0.8749)  loss: 0.7702 (0.8749)\n",
            "Test:  [ 0/62]  eta: 0:03:21  loss_labels: 0.8371 (0.8371)  loss: 0.8371 (0.8371)  time: 3.2553\n",
            "Test:  [61/62]  eta: 0:00:02  loss_labels: 0.7822 (0.7923)  loss: 0.7757 (0.7923)  time: 2.5487\n",
            "Test: Total time: 0:02:33 (2.4691 s / it)\n",
            "Averaged stats: loss_labels: 0.7822 (0.7923)  loss: 0.7757 (0.7923)\n",
            "100% 19004/19004 [00:07<00:00, 2508.65it/s]\n",
            "100% 20544/20544 [00:08<00:00, 2402.50it/s]\n",
            "val_perf: 0.4386846531082671\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [01:42<00:00, 10.25s/it]\n",
            "Epoch: [1]  [  0/554]  eta: 0:12:43  lr: 0.000500  loss_labels: 0.7175 (0.7175)  loss: 0.7175 (0.7175)  time: 1.3784\n",
            "Epoch: [1]  [100/554]  eta: 0:09:53  lr: 0.000500  loss_labels: 0.7959 (0.7968)  loss: 0.8104 (0.7968)  time: 1.3092\n",
            "Epoch: [1]  [200/554]  eta: 0:07:43  lr: 0.000500  loss_labels: 0.7649 (0.7854)  loss: 0.7636 (0.7854)  time: 1.3138\n",
            "Epoch: [1]  [300/554]  eta: 0:05:32  lr: 0.000500  loss_labels: 0.7664 (0.7845)  loss: 0.8048 (0.7845)  time: 1.3177\n",
            "Epoch: [1]  [400/554]  eta: 0:03:21  lr: 0.000500  loss_labels: 0.7473 (0.7784)  loss: 0.7472 (0.7784)  time: 1.3187\n",
            "Epoch: [1]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.7563 (0.7769)  loss: 0.7282 (0.7769)  time: 1.3125\n",
            "Epoch: [1]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7514 (0.7756)  loss: 0.7518 (0.7756)  time: 1.2789\n",
            "Epoch: [1] Total time: 0:12:06 (1.3105 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7514 (0.7756)  loss: 0.7518 (0.7756)\n",
            "Test:  [ 0/62]  eta: 0:01:21  loss_labels: 0.7943 (0.7943)  loss: 0.7943 (0.7943)  time: 1.3153\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7526 (0.7642)  loss: 0.7458 (0.7642)  time: 1.3020\n",
            "Test: Total time: 0:01:21 (1.3150 s / it)\n",
            "Averaged stats: loss_labels: 0.7526 (0.7642)  loss: 0.7458 (0.7642)\n",
            "100% 19004/19004 [00:08<00:00, 2143.48it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2223.37it/s]\n",
            "val_perf: 0.45439393590013866\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:15<00:00,  1.59s/it]\n",
            "Epoch: [2]  [  0/554]  eta: 0:11:55  lr: 0.000500  loss_labels: 0.7564 (0.7564)  loss: 0.7564 (0.7564)  time: 1.2918\n",
            "Epoch: [2]  [100/554]  eta: 0:09:58  lr: 0.000500  loss_labels: 0.7524 (0.7614)  loss: 0.7381 (0.7614)  time: 1.3089\n",
            "Epoch: [2]  [200/554]  eta: 0:07:45  lr: 0.000500  loss_labels: 0.7510 (0.7594)  loss: 0.7179 (0.7594)  time: 1.3119\n",
            "Epoch: [2]  [300/554]  eta: 0:05:33  lr: 0.000500  loss_labels: 0.7449 (0.7569)  loss: 0.7274 (0.7569)  time: 1.3127\n",
            "Epoch: [2]  [400/554]  eta: 0:03:22  lr: 0.000500  loss_labels: 0.7394 (0.7544)  loss: 0.7551 (0.7544)  time: 1.3170\n",
            "Epoch: [2]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.7423 (0.7537)  loss: 0.7854 (0.7537)  time: 1.3220\n",
            "Epoch: [2]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7414 (0.7524)  loss: 0.7493 (0.7524)  time: 1.2888\n",
            "Epoch: [2] Total time: 0:12:07 (1.3138 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7414 (0.7524)  loss: 0.7493 (0.7524)\n",
            "Test:  [ 0/62]  eta: 0:01:21  loss_labels: 0.7637 (0.7637)  loss: 0.7637 (0.7637)  time: 1.3104\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7459 (0.7528)  loss: 0.7564 (0.7528)  time: 1.2970\n",
            "Test: Total time: 0:01:23 (1.3450 s / it)\n",
            "Averaged stats: loss_labels: 0.7459 (0.7528)  loss: 0.7564 (0.7528)\n",
            "100% 19004/19004 [00:08<00:00, 2330.58it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2214.28it/s]\n",
            "val_perf: 0.4625697777406242\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:16<00:00,  1.69s/it]\n",
            "Epoch: [3]  [  0/554]  eta: 0:11:53  lr: 0.000500  loss_labels: 0.6430 (0.6430)  loss: 0.6430 (0.6430)  time: 1.2884\n",
            "Epoch: [3]  [100/554]  eta: 0:09:55  lr: 0.000500  loss_labels: 0.7454 (0.7441)  loss: 0.7442 (0.7441)  time: 1.3046\n",
            "Epoch: [3]  [200/554]  eta: 0:07:43  lr: 0.000500  loss_labels: 0.7305 (0.7459)  loss: 0.7519 (0.7459)  time: 1.3155\n",
            "Epoch: [3]  [300/554]  eta: 0:05:33  lr: 0.000500  loss_labels: 0.7271 (0.7431)  loss: 0.6999 (0.7431)  time: 1.3180\n",
            "Epoch: [3]  [400/554]  eta: 0:03:22  lr: 0.000500  loss_labels: 0.7278 (0.7421)  loss: 0.7371 (0.7421)  time: 1.3139\n",
            "Epoch: [3]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.7235 (0.7413)  loss: 0.7264 (0.7413)  time: 1.3159\n",
            "Epoch: [3]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7235 (0.7400)  loss: 0.7183 (0.7400)  time: 1.2912\n",
            "Epoch: [3] Total time: 0:12:07 (1.3131 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7235 (0.7400)  loss: 0.7183 (0.7400)\n",
            "Test:  [ 0/62]  eta: 0:01:21  loss_labels: 0.7782 (0.7782)  loss: 0.7782 (0.7782)  time: 1.3067\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7359 (0.7465)  loss: 0.7380 (0.7465)  time: 1.2835\n",
            "Test: Total time: 0:01:20 (1.3041 s / it)\n",
            "Averaged stats: loss_labels: 0.7359 (0.7465)  loss: 0.7380 (0.7465)\n",
            "100% 19004/19004 [00:08<00:00, 2213.88it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2191.02it/s]\n",
            "val_perf: 0.4693587110180809\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:16<00:00,  1.61s/it]\n",
            "Epoch: [4]  [  0/554]  eta: 0:12:27  lr: 0.000500  loss_labels: 0.6863 (0.6863)  loss: 0.6863 (0.6863)  time: 1.3496\n",
            "Epoch: [4]  [100/554]  eta: 0:09:56  lr: 0.000500  loss_labels: 0.7055 (0.7216)  loss: 0.6851 (0.7216)  time: 1.3039\n",
            "Epoch: [4]  [200/554]  eta: 0:07:43  lr: 0.000500  loss_labels: 0.7177 (0.7296)  loss: 0.6976 (0.7296)  time: 1.3120\n",
            "Epoch: [4]  [300/554]  eta: 0:05:32  lr: 0.000500  loss_labels: 0.7253 (0.7302)  loss: 0.7236 (0.7302)  time: 1.3169\n",
            "Epoch: [4]  [400/554]  eta: 0:03:22  lr: 0.000500  loss_labels: 0.7239 (0.7308)  loss: 0.7235 (0.7308)  time: 1.3335\n",
            "Epoch: [4]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.7139 (0.7298)  loss: 0.6975 (0.7298)  time: 1.3222\n",
            "Epoch: [4]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7099 (0.7292)  loss: 0.7006 (0.7292)  time: 1.2947\n",
            "Epoch: [4] Total time: 0:12:08 (1.3153 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7099 (0.7292)  loss: 0.7006 (0.7292)\n",
            "Test:  [ 0/62]  eta: 0:01:20  loss_labels: 0.7825 (0.7825)  loss: 0.7825 (0.7825)  time: 1.3055\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7332 (0.7426)  loss: 0.7332 (0.7426)  time: 1.2973\n",
            "Test: Total time: 0:01:21 (1.3175 s / it)\n",
            "Averaged stats: loss_labels: 0.7332 (0.7426)  loss: 0.7332 (0.7426)\n",
            "100% 19004/19004 [00:09<00:00, 2029.99it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2172.68it/s]\n",
            "val_perf: 0.47085953100016575\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:16<00:00,  1.66s/it]\n",
            "Epoch: [5]  [  0/554]  eta: 0:12:02  lr: 0.000500  loss_labels: 0.6869 (0.6869)  loss: 0.6869 (0.6869)  time: 1.3044\n",
            "Epoch: [5]  [100/554]  eta: 0:09:57  lr: 0.000500  loss_labels: 0.7009 (0.7077)  loss: 0.7318 (0.7077)  time: 1.3129\n",
            "Epoch: [5]  [200/554]  eta: 0:07:44  lr: 0.000500  loss_labels: 0.7234 (0.7195)  loss: 0.7509 (0.7195)  time: 1.3130\n",
            "Epoch: [5]  [300/554]  eta: 0:05:35  lr: 0.000500  loss_labels: 0.7084 (0.7193)  loss: 0.6851 (0.7193)  time: 1.3421\n",
            "Epoch: [5]  [400/554]  eta: 0:03:25  lr: 0.000500  loss_labels: 0.7061 (0.7186)  loss: 0.7132 (0.7186)  time: 1.4403\n",
            "Epoch: [5]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.7261 (0.7203)  loss: 0.6975 (0.7203)  time: 1.3296\n",
            "Epoch: [5]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7146 (0.7213)  loss: 0.6935 (0.7213)  time: 1.2915\n",
            "Epoch: [5] Total time: 0:12:17 (1.3310 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7146 (0.7213)  loss: 0.6935 (0.7213)\n",
            "Test:  [ 0/62]  eta: 0:01:25  loss_labels: 0.7860 (0.7860)  loss: 0.7860 (0.7860)  time: 1.3730\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7403 (0.7474)  loss: 0.7354 (0.7474)  time: 1.3134\n",
            "Test: Total time: 0:01:21 (1.3215 s / it)\n",
            "Averaged stats: loss_labels: 0.7403 (0.7474)  loss: 0.7354 (0.7474)\n",
            "100% 19004/19004 [00:08<00:00, 2229.25it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2127.32it/s]\n",
            "val_perf: 0.47091353837774036\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:15<00:00,  1.60s/it]\n",
            "Epoch: [6]  [  0/554]  eta: 0:12:52  lr: 0.000500  loss_labels: 0.7275 (0.7275)  loss: 0.7275 (0.7275)  time: 1.3950\n",
            "Epoch: [6]  [100/554]  eta: 0:10:00  lr: 0.000500  loss_labels: 0.6943 (0.7019)  loss: 0.6914 (0.7019)  time: 1.3275\n",
            "Epoch: [6]  [200/554]  eta: 0:07:47  lr: 0.000500  loss_labels: 0.7053 (0.7111)  loss: 0.6917 (0.7111)  time: 1.3237\n",
            "Epoch: [6]  [300/554]  eta: 0:05:35  lr: 0.000500  loss_labels: 0.7062 (0.7107)  loss: 0.6808 (0.7107)  time: 1.3186\n",
            "Epoch: [6]  [400/554]  eta: 0:03:23  lr: 0.000500  loss_labels: 0.7050 (0.7115)  loss: 0.6767 (0.7115)  time: 1.3290\n",
            "Epoch: [6]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.7153 (0.7148)  loss: 0.7153 (0.7148)  time: 1.3344\n",
            "Epoch: [6]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7044 (0.7147)  loss: 0.6797 (0.7147)  time: 1.2936\n",
            "Epoch: [6] Total time: 0:12:12 (1.3220 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7044 (0.7147)  loss: 0.6797 (0.7147)\n",
            "Test:  [ 0/62]  eta: 0:01:22  loss_labels: 0.7862 (0.7862)  loss: 0.7862 (0.7862)  time: 1.3309\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7381 (0.7458)  loss: 0.7414 (0.7458)  time: 1.2992\n",
            "Test: Total time: 0:01:21 (1.3170 s / it)\n",
            "Averaged stats: loss_labels: 0.7381 (0.7458)  loss: 0.7414 (0.7458)\n",
            "100% 19004/19004 [00:08<00:00, 2295.40it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2120.09it/s]\n",
            "val_perf: 0.4720636864603158\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:16<00:00,  1.65s/it]\n",
            "Epoch: [7]  [  0/554]  eta: 0:11:57  lr: 0.000500  loss_labels: 0.7450 (0.7450)  loss: 0.7450 (0.7450)  time: 1.2959\n",
            "Epoch: [7]  [100/554]  eta: 0:09:58  lr: 0.000500  loss_labels: 0.6832 (0.6955)  loss: 0.6939 (0.6955)  time: 1.3117\n",
            "Epoch: [7]  [200/554]  eta: 0:07:46  lr: 0.000500  loss_labels: 0.7162 (0.7085)  loss: 0.7070 (0.7085)  time: 1.3157\n",
            "Epoch: [7]  [300/554]  eta: 0:05:35  lr: 0.000500  loss_labels: 0.6909 (0.7066)  loss: 0.7000 (0.7066)  time: 1.3247\n",
            "Epoch: [7]  [400/554]  eta: 0:03:23  lr: 0.000500  loss_labels: 0.7041 (0.7066)  loss: 0.7176 (0.7066)  time: 1.3231\n",
            "Epoch: [7]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.7010 (0.7078)  loss: 0.7397 (0.7078)  time: 1.3166\n",
            "Epoch: [7]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.7027 (0.7077)  loss: 0.6757 (0.7077)  time: 1.3018\n",
            "Epoch: [7] Total time: 0:12:11 (1.3212 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.7027 (0.7077)  loss: 0.6757 (0.7077)\n",
            "Test:  [ 0/62]  eta: 0:01:21  loss_labels: 0.7579 (0.7579)  loss: 0.7579 (0.7579)  time: 1.3070\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7358 (0.7425)  loss: 0.7370 (0.7425)  time: 1.2943\n",
            "Test: Total time: 0:01:21 (1.3124 s / it)\n",
            "Averaged stats: loss_labels: 0.7358 (0.7425)  loss: 0.7370 (0.7425)\n",
            "100% 19004/19004 [00:08<00:00, 2168.49it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2054.51it/s]\n",
            "val_perf: 0.4756489288303508\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "100% 10/10 [00:16<00:00,  1.67s/it]\n",
            "Epoch: [8]  [  0/554]  eta: 0:12:31  lr: 0.000500  loss_labels: 0.7274 (0.7274)  loss: 0.7274 (0.7274)  time: 1.3561\n",
            "Epoch: [8]  [100/554]  eta: 0:09:58  lr: 0.000500  loss_labels: 0.6918 (0.6924)  loss: 0.6519 (0.6924)  time: 1.3138\n",
            "Epoch: [8]  [200/554]  eta: 0:07:46  lr: 0.000500  loss_labels: 0.7015 (0.7008)  loss: 0.7094 (0.7008)  time: 1.3184\n",
            "Epoch: [8]  [300/554]  eta: 0:05:34  lr: 0.000500  loss_labels: 0.6794 (0.6974)  loss: 0.6644 (0.6974)  time: 1.3221\n",
            "Epoch: [8]  [400/554]  eta: 0:03:23  lr: 0.000500  loss_labels: 0.7012 (0.7006)  loss: 0.6907 (0.7006)  time: 1.3279\n",
            "Epoch: [8]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.6936 (0.7008)  loss: 0.6998 (0.7008)  time: 1.3313\n",
            "Epoch: [8]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6990 (0.7013)  loss: 0.7283 (0.7013)  time: 1.2905\n",
            "Epoch: [8] Total time: 0:12:11 (1.3206 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6990 (0.7013)  loss: 0.7283 (0.7013)\n",
            "Test:  [ 0/62]  eta: 0:01:21  loss_labels: 0.7964 (0.7964)  loss: 0.7964 (0.7964)  time: 1.3071\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7385 (0.7462)  loss: 0.7426 (0.7462)  time: 1.3027\n",
            "Test: Total time: 0:01:21 (1.3216 s / it)\n",
            "Averaged stats: loss_labels: 0.7385 (0.7462)  loss: 0.7426 (0.7462)\n",
            "100% 19004/19004 [00:09<00:00, 2026.48it/s]\n",
            "100% 20544/20544 [00:08<00:00, 2391.97it/s]\n",
            "val_perf: 0.4743351608373925\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "Epoch: [9]  [  0/554]  eta: 0:12:32  lr: 0.000500  loss_labels: 0.6400 (0.6400)  loss: 0.6400 (0.6400)  time: 1.3584\n",
            "Epoch: [9]  [100/554]  eta: 0:09:57  lr: 0.000500  loss_labels: 0.6789 (0.6885)  loss: 0.6652 (0.6885)  time: 1.3173\n",
            "Epoch: [9]  [200/554]  eta: 0:07:44  lr: 0.000500  loss_labels: 0.6884 (0.6927)  loss: 0.6891 (0.6927)  time: 1.3176\n",
            "Epoch: [9]  [300/554]  eta: 0:05:33  lr: 0.000500  loss_labels: 0.6809 (0.6921)  loss: 0.7162 (0.6921)  time: 1.3182\n",
            "Epoch: [9]  [400/554]  eta: 0:03:22  lr: 0.000500  loss_labels: 0.6929 (0.6942)  loss: 0.6738 (0.6942)  time: 1.3177\n",
            "Epoch: [9]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.6975 (0.6956)  loss: 0.7012 (0.6956)  time: 1.3221\n",
            "Epoch: [9]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6968 (0.6956)  loss: 0.6929 (0.6956)  time: 1.3007\n",
            "Epoch: [9] Total time: 0:12:09 (1.3176 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6968 (0.6956)  loss: 0.6929 (0.6956)\n",
            "Test:  [ 0/62]  eta: 0:01:22  loss_labels: 0.7766 (0.7766)  loss: 0.7766 (0.7766)  time: 1.3318\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7319 (0.7422)  loss: 0.7319 (0.7422)  time: 1.2903\n",
            "Test: Total time: 0:01:21 (1.3207 s / it)\n",
            "Averaged stats: loss_labels: 0.7319 (0.7422)  loss: 0.7319 (0.7422)\n",
            "100% 19004/19004 [00:08<00:00, 2172.50it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2077.47it/s]\n",
            "val_perf: 0.47268782461835834\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "Epoch: [10]  [  0/554]  eta: 0:12:55  lr: 0.000500  loss_labels: 0.6539 (0.6539)  loss: 0.6539 (0.6539)  time: 1.4001\n",
            "Epoch: [10]  [100/554]  eta: 0:09:55  lr: 0.000500  loss_labels: 0.6796 (0.6871)  loss: 0.6982 (0.6871)  time: 1.3098\n",
            "Epoch: [10]  [200/554]  eta: 0:07:43  lr: 0.000500  loss_labels: 0.6750 (0.6864)  loss: 0.6854 (0.6864)  time: 1.3207\n",
            "Epoch: [10]  [300/554]  eta: 0:05:33  lr: 0.000500  loss_labels: 0.6710 (0.6845)  loss: 0.6912 (0.6845)  time: 1.3167\n",
            "Epoch: [10]  [400/554]  eta: 0:03:22  lr: 0.000500  loss_labels: 0.6882 (0.6867)  loss: 0.7066 (0.6867)  time: 1.3247\n",
            "Epoch: [10]  [500/554]  eta: 0:01:11  lr: 0.000500  loss_labels: 0.6864 (0.6876)  loss: 0.6912 (0.6876)  time: 1.3296\n",
            "Epoch: [10]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6797 (0.6888)  loss: 0.6970 (0.6888)  time: 1.2964\n",
            "Epoch: [10] Total time: 0:12:08 (1.3152 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6797 (0.6888)  loss: 0.6970 (0.6888)\n",
            "Test:  [ 0/62]  eta: 0:01:21  loss_labels: 0.7672 (0.7672)  loss: 0.7672 (0.7672)  time: 1.3196\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7311 (0.7414)  loss: 0.7326 (0.7414)  time: 1.3168\n",
            "Test: Total time: 0:01:21 (1.3209 s / it)\n",
            "Averaged stats: loss_labels: 0.7311 (0.7414)  loss: 0.7326 (0.7414)\n",
            "100% 19004/19004 [00:09<00:00, 2087.67it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2133.21it/s]\n",
            "val_perf: 0.4714152831699864\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "Epoch: [11]  [  0/554]  eta: 0:12:34  lr: 0.000500  loss_labels: 0.6463 (0.6463)  loss: 0.6463 (0.6463)  time: 1.3616\n",
            "Epoch: [11]  [100/554]  eta: 0:09:52  lr: 0.000500  loss_labels: 0.6579 (0.6636)  loss: 0.6501 (0.6636)  time: 1.3090\n",
            "Epoch: [11]  [200/554]  eta: 0:07:42  lr: 0.000500  loss_labels: 0.6703 (0.6710)  loss: 0.6586 (0.6710)  time: 1.3009\n",
            "Epoch: [11]  [300/554]  eta: 0:05:32  lr: 0.000500  loss_labels: 0.6880 (0.6795)  loss: 0.6925 (0.6795)  time: 1.3141\n",
            "Epoch: [11]  [400/554]  eta: 0:03:21  lr: 0.000500  loss_labels: 0.6830 (0.6814)  loss: 0.6678 (0.6814)  time: 1.3174\n",
            "Epoch: [11]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.6703 (0.6823)  loss: 0.6566 (0.6823)  time: 1.3262\n",
            "Epoch: [11]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6703 (0.6824)  loss: 0.6648 (0.6824)  time: 1.2965\n",
            "Epoch: [11] Total time: 0:12:07 (1.3126 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6703 (0.6824)  loss: 0.6648 (0.6824)\n",
            "Test:  [ 0/62]  eta: 0:01:19  loss_labels: 0.7749 (0.7749)  loss: 0.7749 (0.7749)  time: 1.2841\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7384 (0.7507)  loss: 0.7373 (0.7507)  time: 1.2764\n",
            "Test: Total time: 0:01:20 (1.2914 s / it)\n",
            "Averaged stats: loss_labels: 0.7384 (0.7507)  loss: 0.7373 (0.7507)\n",
            "100% 19004/19004 [00:09<00:00, 2074.93it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2220.42it/s]\n",
            "val_perf: 0.4674921224709182\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "Epoch: [12]  [  0/554]  eta: 0:12:25  lr: 0.000500  loss_labels: 0.7760 (0.7760)  loss: 0.7760 (0.7760)  time: 1.3452\n",
            "Epoch: [12]  [100/554]  eta: 0:09:52  lr: 0.000500  loss_labels: 0.6609 (0.6684)  loss: 0.6472 (0.6684)  time: 1.3091\n",
            "Epoch: [12]  [200/554]  eta: 0:07:41  lr: 0.000500  loss_labels: 0.6706 (0.6727)  loss: 0.6523 (0.6727)  time: 1.3034\n",
            "Epoch: [12]  [300/554]  eta: 0:05:30  lr: 0.000500  loss_labels: 0.6615 (0.6751)  loss: 0.6840 (0.6751)  time: 1.3083\n",
            "Epoch: [12]  [400/554]  eta: 0:03:20  lr: 0.000500  loss_labels: 0.6764 (0.6767)  loss: 0.6764 (0.6767)  time: 1.3096\n",
            "Epoch: [12]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.6808 (0.6776)  loss: 0.6738 (0.6776)  time: 1.3219\n",
            "Epoch: [12]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6658 (0.6763)  loss: 0.6642 (0.6763)  time: 1.2850\n",
            "Epoch: [12] Total time: 0:12:03 (1.3064 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6658 (0.6763)  loss: 0.6642 (0.6763)\n",
            "Test:  [ 0/62]  eta: 0:01:24  loss_labels: 0.7685 (0.7685)  loss: 0.7685 (0.7685)  time: 1.3679\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7394 (0.7492)  loss: 0.7330 (0.7492)  time: 1.2927\n",
            "Test: Total time: 0:01:20 (1.3061 s / it)\n",
            "Averaged stats: loss_labels: 0.7394 (0.7492)  loss: 0.7330 (0.7492)\n",
            "100% 19004/19004 [00:07<00:00, 2575.91it/s]\n",
            "100% 20544/20544 [00:10<00:00, 2016.47it/s]\n",
            "val_perf: 0.46635408802513556\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "Epoch: [13]  [  0/554]  eta: 0:12:21  lr: 0.000500  loss_labels: 0.6545 (0.6545)  loss: 0.6545 (0.6545)  time: 1.3386\n",
            "Epoch: [13]  [100/554]  eta: 0:09:51  lr: 0.000500  loss_labels: 0.6597 (0.6648)  loss: 0.6465 (0.6648)  time: 1.3092\n",
            "Epoch: [13]  [200/554]  eta: 0:07:40  lr: 0.000500  loss_labels: 0.6572 (0.6636)  loss: 0.6738 (0.6636)  time: 1.3076\n",
            "Epoch: [13]  [300/554]  eta: 0:05:30  lr: 0.000500  loss_labels: 0.6568 (0.6638)  loss: 0.6633 (0.6638)  time: 1.3100\n",
            "Epoch: [13]  [400/554]  eta: 0:03:20  lr: 0.000500  loss_labels: 0.6593 (0.6667)  loss: 0.6738 (0.6667)  time: 1.3089\n",
            "Epoch: [13]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.6660 (0.6691)  loss: 0.6706 (0.6691)  time: 1.3132\n",
            "Epoch: [13]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6706 (0.6701)  loss: 0.6710 (0.6701)  time: 1.2781\n",
            "Epoch: [13] Total time: 0:12:01 (1.3019 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6706 (0.6701)  loss: 0.6710 (0.6701)\n",
            "Test:  [ 0/62]  eta: 0:01:20  loss_labels: 0.7473 (0.7473)  loss: 0.7473 (0.7473)  time: 1.2933\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7411 (0.7529)  loss: 0.7411 (0.7529)  time: 1.2693\n",
            "Test: Total time: 0:01:20 (1.2938 s / it)\n",
            "Averaged stats: loss_labels: 0.7411 (0.7529)  loss: 0.7411 (0.7529)\n",
            "100% 19004/19004 [00:08<00:00, 2131.47it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2185.04it/s]\n",
            "val_perf: 0.46465041559761094\n",
            "shape of rh_fmri_val_pred (984, 20544)\n",
            "Epoch: [14]  [  0/554]  eta: 0:12:14  lr: 0.000500  loss_labels: 0.7002 (0.7002)  loss: 0.7002 (0.7002)  time: 1.3263\n",
            "Epoch: [14]  [100/554]  eta: 0:09:52  lr: 0.000500  loss_labels: 0.6522 (0.6552)  loss: 0.6295 (0.6552)  time: 1.3019\n",
            "Epoch: [14]  [200/554]  eta: 0:07:41  lr: 0.000500  loss_labels: 0.6364 (0.6513)  loss: 0.6462 (0.6513)  time: 1.3071\n",
            "Epoch: [14]  [300/554]  eta: 0:05:30  lr: 0.000500  loss_labels: 0.6495 (0.6539)  loss: 0.6485 (0.6539)  time: 1.3059\n",
            "Epoch: [14]  [400/554]  eta: 0:03:20  lr: 0.000500  loss_labels: 0.6798 (0.6598)  loss: 0.6935 (0.6598)  time: 1.2951\n",
            "Epoch: [14]  [500/554]  eta: 0:01:10  lr: 0.000500  loss_labels: 0.6790 (0.6636)  loss: 0.6675 (0.6636)  time: 1.3007\n",
            "Epoch: [14]  [553/554]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.6675 (0.6642)  loss: 0.6488 (0.6642)  time: 1.2797\n",
            "Epoch: [14] Total time: 0:12:00 (1.3012 s / it)\n",
            "Averaged stats: lr: 0.000500  loss_labels: 0.6675 (0.6642)  loss: 0.6488 (0.6642)\n",
            "Test:  [ 0/62]  eta: 0:01:20  loss_labels: 0.7729 (0.7729)  loss: 0.7729 (0.7729)  time: 1.3021\n",
            "Test:  [61/62]  eta: 0:00:01  loss_labels: 0.7470 (0.7532)  loss: 0.7474 (0.7532)  time: 1.2817\n",
            "Test: Total time: 0:01:20 (1.2999 s / it)\n",
            "Averaged stats: loss_labels: 0.7470 (0.7532)  loss: 0.7474 (0.7532)\n",
            "100% 19004/19004 [00:09<00:00, 2089.72it/s]\n",
            "100% 20544/20544 [00:09<00:00, 2170.42it/s]\n",
            "val_perf: 0.4628704716425356\n",
            "shape of rh_fmri_val_pred (984, 20544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd /content/transformer_brain_encoder && python main.py \\\n",
        "  --subj args.subj \\\n",
        "  --run 1 \\\n",
        "  --data_dir '/content/drive/MyDrive/algonauts_2023_tutorial_data' \\\n",
        "  --dataset 'nsd_algo' \\\n",
        "  --backbone_arch 'dinov2_q' \\\n",
        "  --encoder_arch 'spatial_feature' \\\n",
        "  --readout_res 'rois_all' \\\n",
        "  --epochs 2 \\\n",
        "  --batch_size 8 \\\n",
        "  --image_size 224 \\\n",
        "  --output_path './results/' \\\n",
        "  --save_model 0 \\\n",
        "  --enc_output_layer 1 \\\n",
        "  --lr 0.0005 \\\n",
        "  --lr_drop 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Av7O-_XlnU_",
        "outputId": "f5cd103e-d173-4d41-bb7e-a779c50b2fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "roi_name_maps: [{0: 'Unknown', 1: 'V1v', 2: 'V1d', 3: 'V2v', 4: 'V2d', 5: 'V3v', 6: 'V3d', 7: 'hV4'}, {0: 'Unknown', 1: 'EBA', 2: 'FBA-1', 3: 'FBA-2', 4: 'mTL-bodies'}, {0: 'Unknown', 1: 'OFA', 2: 'FFA-1', 3: 'FFA-2', 4: 'mTL-faces', 5: 'aTL-faces'}, {0: 'Unknown', 1: 'OPA', 2: 'PPA', 3: 'RSC'}, {0: 'Unknown', 1: 'OWFA', 2: 'VWFA-1', 3: 'VWFA-2', 4: 'mfs-words', 5: 'mTL-words'}, {0: 'Unknown', 1: 'early', 2: 'midventral', 3: 'midlateral', 4: 'midparietal', 5: 'ventral', 6: 'lateral', 7: 'parietal'}]\n",
            "lh_challenge_rois: 6\n",
            "lh_challenge_rois_s: torch.Size([25, 19004])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/transformer_brain_encoder/main.py\", line 491, in <module>\n",
            "    main(0, 1, args)\n",
            "  File \"/content/transformer_brain_encoder/main.py\", line 258, in main\n",
            "    train_loader, val_loader = fetch_dataloaders(args, train='train')\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/transformer_brain_encoder/datasets/nsd.py\", line 251, in fetch_dataloaders\n",
            "    algonauts_dataset(args,train, train_imgs_paths, idxs_train, transform_train), \n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/transformer_brain_encoder/datasets/nsd.py\", line 44, in __init__\n",
            "    rh_fmri = np.load(os.path.join(fmri_dir, 'rh_training_fmri.npy'))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\", line 484, in load\n",
            "    return format.read_array(fid, allow_pickle=allow_pickle,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/format.py\", line 836, in read_array\n",
            "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}